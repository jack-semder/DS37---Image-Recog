{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quickdraw_ParamTuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "[Quickdraw](https://github.com/googlecreativelab/quickdraw-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxctNMPb7mNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e559b4d-f5fe-4160-a177-cb7d14d095a8"
      },
      "source": [
        "# native python libraries imports \n",
        "import math\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# sklearn imports \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# keras imports \n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.activations import relu, sigmoid\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "# required for compatibility between sklearn and keras\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# install keras-tuner\n",
        "!pip install keras-tuner\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr8w6IX37mNa"
      },
      "source": [
        "def load_quickdraw10():\n",
        "    \"\"\"\n",
        "    Fill out this doc string, and comment the code, for practice in writing the kind of code that will get you hired. \n",
        "    \"\"\"\n",
        "    \n",
        "    URL_ = \"https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\"\n",
        "    \n",
        "    path_to_zip = get_file('./quickdraw10.npz', origin=URL_, extract=False)\n",
        "\n",
        "    data = np.load(path_to_zip)\n",
        "    \n",
        "    # normalize \n",
        "    max_pixel_value = 255\n",
        "    X = data['arr_0']/max_pixel_value\n",
        "    Y = data['arr_1']\n",
        "        \n",
        "    return train_test_split(X, Y, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjU5nY3e7mNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d938f8ea-6882-420c-ec26-551e20c75a63"
      },
      "source": [
        "X_train, X_test, y_train, y_test = load_quickdraw10()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\n",
            "25427968/25421363 [==============================] - 0s 0us/step\n",
            "25436160/25421363 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkvBPoUy7mNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3f46d3-05d6-4c3d-f563-d6b3fb6ca9b6"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4dx6VA07mNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e590e324-d06f-4b01-941b-308e6a49abd1"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXsWtj8Z7mNf"
      },
      "source": [
        "\n",
        "\n",
        "## Tune Hyperperameters w/ GridsearchCV \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy"
      },
      "source": [
        "def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
        "        \"\"\"\n",
        "        Generates and returns the number of nodes in each hidden layer. \n",
        "        To be clear, this excludes the input and output layer. \n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        Number of nodes in each layer is linearly incremented. \n",
        "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_layers: int\n",
        "            Number of hidden layers\n",
        "            This values should be 2 or greater \n",
        "\n",
        "        first_layer_nodes: int\n",
        "\n",
        "        last_layer_nodes: int\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        layers: list of ints\n",
        "            Contains number of nodes for each layer \n",
        "        \"\"\"\n",
        "\n",
        "        # throws an error if n_layers is less than 2 \n",
        "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        if negative_node_incrementation:\n",
        "            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "            \n",
        "        # when set to False number of nodes are increased for subsequent layers\n",
        "        else:\n",
        "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "\n",
        "        nodes = first_layer_nodes\n",
        "\n",
        "        for i in range(1, n_layers+1):\n",
        "\n",
        "            layers.append(math.ceil(nodes))\n",
        "\n",
        "            # increment nodes for next layer \n",
        "            nodes = nodes + nodes_increment\n",
        "\n",
        "        return layers\n",
        "\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n",
        "    \"\"\"\"\n",
        "    Returns a compiled keras model \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_layers: int \n",
        "        number of hidden layers in model \n",
        "        To be clear, this excludes the input and output layer.\n",
        "        \n",
        "    first_layer_nodes: int\n",
        "        Number of nodes in the first hidden layer \n",
        "\n",
        "    last_layer_nodes: int\n",
        "        Number of nodes in the last hidden layer (this is the layer just prior to the output layer)\n",
        "        \n",
        "     act_funct: string \n",
        "         Name of activation function to use in hidden layers (this excludes the output layer)\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    model: keras object \n",
        "    \"\"\"\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
        "    \n",
        "    for i in range(1, n_layers):\n",
        "        if i==1:\n",
        "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=act_funct))\n",
        "        else:\n",
        "            model.add(Dense(n_nodes[i-1], activation=act_funct))\n",
        "            \n",
        "            \n",
        "    # output layer \n",
        "    model.add(Dense(10, # 10 unit/neurons in output layer because we have 10 possible labels to predict  \n",
        "                    activation='softmax')) # use softmax for a label set greater than 2            \n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='sparse_categorical_crossentropy', \n",
        "                  optimizer='adam', # adam is a good default optimizer \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # do not include model.fit() inside the create_model function\n",
        "    # KerasClassifier is expecting a complied model \n",
        "    return model\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
        "        \"\"\"\n",
        "        Generates and returns the number of nodes in each hidden layer. \n",
        "        To be clear, this excludes the input and output layer. \n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        Number of nodes in each layer is linearly incremented. \n",
        "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_layers: int\n",
        "            Number of hidden layers\n",
        "            This values should be 2 or greater \n",
        "\n",
        "        first_layer_nodes: int\n",
        "\n",
        "        last_layer_nodes: int\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        layers: list of ints\n",
        "            Contains number of nodes for each layer \n",
        "        \"\"\"\n",
        "\n",
        "        # throws an error if n_layers is less than 2 \n",
        "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        if negative_node_incrementation:\n",
        "            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "            #print(f'nodes increment = {nodes_increment}')\n",
        "            \n",
        "        # when set to False number of nodes are increased for subsequent layers\n",
        "        else:\n",
        "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "            #print(f'nodes increment = {nodes_increment}')\n",
        "\n",
        "        nodes = first_layer_nodes\n",
        "\n",
        "        for i in range(1, n_layers+1):\n",
        "\n",
        "            layers.append(math.ceil(nodes))\n",
        "\n",
        "            # increment nodes for next layer \n",
        "            nodes = nodes + nodes_increment\n",
        "\n",
        "        return layers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YiPXu0p_Qco_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `negative_node_incrementation = True` "
      ],
      "metadata": {
        "id": "Mj3MrB6jXUMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 5\n",
        "first_layer_nodes = 500\n",
        "last_layer_nodes = 100\n",
        "negative_node_incrementation = True\n",
        "n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
        "print(f'Number of nodes in successive layers: {n_nodes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m4jRNllXPPG",
        "outputId": "abce8a53-ce58-4c0b-bed3-86024ec030ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes in successive layers: [500, 400, 300, 200, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `negative_node_incrementation = False`"
      ],
      "metadata": {
        "id": "ttkaf3g9XhGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 5\n",
        "first_layer_nodes = 100\n",
        "last_layer_nodes = 500\n",
        "negative_node_incrementation = False\n",
        "n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
        "print(f'Number of nodes in successive layers: {n_nodes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fkrMS8bXQUo",
        "outputId": "a27a5229-8781-4741-cef0-67fcad09c3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes in successive layers: [100, 200, 300, 400, 500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5dcf5c585f07629a03086cf57ba53615",
          "grade": false,
          "grade_id": "cell-86d63e89a21223de",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "x_1REOCY7mNi"
      },
      "source": [
        "model = create_model(n_layers, first_layer_nodes, last_layer_nodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYMwZQ7k7mNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd1276b6-9400-463b-d3a0-828f1fe8b692"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               20200     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 300)               60300     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 400)               120400    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                4010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 283,410\n",
            "Trainable params: 283,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5dcf5c585f07629a03086cf57ba53615",
          "grade": false,
          "grade_id": "cell-86d63e89a21223de",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3_-kqHQtm-ui"
      },
      "source": [
        "model = create_model(n_layers=10, first_layer_nodes=100, last_layer_nodes=500, act_funct='relu', negative_node_incrementation=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piboKWsNm-uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ab7b0f-48b6-4286-b117-6107369a6a08"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 145)               14645     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 189)               27594     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 234)               44460     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 278)               65330     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 323)               90117     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 367)               118908    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 412)               151616    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 456)               188328    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                4570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 784,068\n",
            "Trainable params: 784,068\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veloj7Nnlttf"
      },
      "source": [
        "### Hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e2lhZqP7mNn"
      },
      "source": [
        "param_grid = {'n_layers': [2, 3],\n",
        "              'epochs': [3], \n",
        "              \"first_layer_nodes\": [500, 300],\n",
        "              \"last_layer_nodes\": [100, 50]\n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ks_MLPB7mNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e439f0bb-0cc3-4710-da11-8424ebdb89f0"
      },
      "source": [
        "model = KerasClassifier(create_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8GKbLJ_7mNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7570b651-5ac0-40b5-f3a7-b7724b209909"
      },
      "source": [
        "%%time\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 13s 5ms/step - loss: 0.6595 - accuracy: 0.8026\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4459 - accuracy: 0.8668\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3587 - accuracy: 0.8933\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4744 - accuracy: 0.8640\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6627 - accuracy: 0.8027\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4512 - accuracy: 0.8671\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3648 - accuracy: 0.8908\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4684 - accuracy: 0.8653\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6621 - accuracy: 0.8017\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4486 - accuracy: 0.8672\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3616 - accuracy: 0.8918\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4663 - accuracy: 0.8617\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6370 - accuracy: 0.8069\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4342 - accuracy: 0.8665\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3471 - accuracy: 0.8927\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.8678\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6363 - accuracy: 0.8072\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4351 - accuracy: 0.8677\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3495 - accuracy: 0.8926\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.8674\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6326 - accuracy: 0.8075\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4306 - accuracy: 0.8676\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3441 - accuracy: 0.8936\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4849 - accuracy: 0.8571\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6635 - accuracy: 0.8015\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4510 - accuracy: 0.8658\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3614 - accuracy: 0.8916\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4682 - accuracy: 0.8641\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6671 - accuracy: 0.8016\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4533 - accuracy: 0.8637\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3633 - accuracy: 0.8922\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4729 - accuracy: 0.8609\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6658 - accuracy: 0.8006\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4551 - accuracy: 0.8654\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3654 - accuracy: 0.8915\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4962 - accuracy: 0.8531\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6364 - accuracy: 0.8058\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4320 - accuracy: 0.8685\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3469 - accuracy: 0.8920\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4561 - accuracy: 0.8682\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6382 - accuracy: 0.8055\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4317 - accuracy: 0.8687\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3438 - accuracy: 0.8945\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4512 - accuracy: 0.8676\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6402 - accuracy: 0.8041\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4335 - accuracy: 0.8684\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3464 - accuracy: 0.8937\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4500 - accuracy: 0.8659\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6834 - accuracy: 0.7954\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4719 - accuracy: 0.8597\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3857 - accuracy: 0.8850\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4835 - accuracy: 0.8607\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6874 - accuracy: 0.7954\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4716 - accuracy: 0.8596\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3878 - accuracy: 0.8840\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4685 - accuracy: 0.8616\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6840 - accuracy: 0.7945\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4695 - accuracy: 0.8601\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3869 - accuracy: 0.8855\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4802 - accuracy: 0.8586\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6494 - accuracy: 0.8012\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4440 - accuracy: 0.8654\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3627 - accuracy: 0.8888\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4719 - accuracy: 0.8620\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6575 - accuracy: 0.7989\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4501 - accuracy: 0.8634\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3687 - accuracy: 0.8868\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4652 - accuracy: 0.8628\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6531 - accuracy: 0.8025\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4455 - accuracy: 0.8642\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3619 - accuracy: 0.8900\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4783 - accuracy: 0.8608\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6871 - accuracy: 0.7955\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4715 - accuracy: 0.8594\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3900 - accuracy: 0.8848\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4827 - accuracy: 0.8591\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6875 - accuracy: 0.7948\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4750 - accuracy: 0.8590\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3896 - accuracy: 0.8839\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4849 - accuracy: 0.8580\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6914 - accuracy: 0.7939\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4742 - accuracy: 0.8594\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3930 - accuracy: 0.8822\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4792 - accuracy: 0.8594\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6590 - accuracy: 0.7988\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4490 - accuracy: 0.8621\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3650 - accuracy: 0.8869\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4806 - accuracy: 0.8598\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6577 - accuracy: 0.8000\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4491 - accuracy: 0.8623\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3621 - accuracy: 0.8902\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4560 - accuracy: 0.8627\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6547 - accuracy: 0.8003\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4494 - accuracy: 0.8637\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3667 - accuracy: 0.8868\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4727 - accuracy: 0.8617\n",
            "Epoch 1/3\n",
            "2344/2344 [==============================] - 7s 3ms/step - loss: 0.5881 - accuracy: 0.8218\n",
            "Epoch 2/3\n",
            "2344/2344 [==============================] - 6s 3ms/step - loss: 0.4065 - accuracy: 0.8759\n",
            "Epoch 3/3\n",
            "2344/2344 [==============================] - 7s 3ms/step - loss: 0.3308 - accuracy: 0.8985\n",
            "Best: 0.8672266801198324 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "Means: 0.8636666536331177, Stdev: 0.0014932185880925325 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n",
            "Means: 0.8641333182652792, Stdev: 0.004961868810771254 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8593733509381613, Stdev: 0.0046153663154185455 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.8672266801198324, Stdev: 0.000983235929794981 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "Means: 0.8602933287620544, Stdev: 0.0012771990079173553 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n",
            "Means: 0.861840009689331, Stdev: 0.0008046436440011743 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8588399887084961, Stdev: 0.0006048720133588444 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.8614133397738138, Stdev: 0.001179548479093737 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "CPU times: user 6min 58s, sys: 39.2 s, total: 7min 38s\n",
            "Wall time: 8min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfH6okqe7mNo"
      },
      "source": [
        "best_model = grid_result.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inlda_0w7mNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31651e77-d4a9-4337-de42-199cb4d40e19"
      },
      "source": [
        "best_model.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'build_fn': <function __main__.create_model>,\n",
              " 'epochs': 3,\n",
              " 'first_layer_nodes': 500,\n",
              " 'last_layer_nodes': 50,\n",
              " 'n_layers': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4ca6c5e51302fd10",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "p-NcKYRr5yYX"
      },
      "source": [
        "# use create_model to create a model \n",
        "model = create_model(n_layers=2, first_layer_nodes=500, last_layer_nodes=100, act_funct='relu', negative_node_incrementation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICLd6cYN5yYY",
        "outputId": "86b624be-5e32-4e20-9c3e-68a2a0228b74"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_78 (Dense)            (None, 500)               392500    \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 10)                5010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 397,510\n",
            "Trainable params: 397,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwY6GFo85yYY"
      },
      "source": [
        "# define the grid search parameters\n",
        "param_grid = {'n_layers': [2, 3],\n",
        "              'epochs': [3], \n",
        "              \"first_layer_nodes\": [500, 300],\n",
        "              \"last_layer_nodes\": [100, 50]\n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a0iHBqJ5yYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb79cf81-eb4d-453d-ba09-c0bbb97103a5"
      },
      "source": [
        "model = KerasClassifier(create_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxpuM3g15yYZ",
        "outputId": "34ebd4ff-5f0d-4856-be8d-7567deffc320"
      },
      "source": [
        "%%time\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6598 - accuracy: 0.8037\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4499 - accuracy: 0.8658\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3598 - accuracy: 0.8919\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4629 - accuracy: 0.8674\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6687 - accuracy: 0.7997\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4542 - accuracy: 0.8645\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3650 - accuracy: 0.8901\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4669 - accuracy: 0.8633\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6627 - accuracy: 0.8012\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4491 - accuracy: 0.8669\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3630 - accuracy: 0.8911\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4564 - accuracy: 0.8669\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6372 - accuracy: 0.8046\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4313 - accuracy: 0.8672\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3447 - accuracy: 0.8943\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4776 - accuracy: 0.8613\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6342 - accuracy: 0.8045\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4320 - accuracy: 0.8693\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3443 - accuracy: 0.8940\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.8646\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6335 - accuracy: 0.8084\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4290 - accuracy: 0.8689\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3425 - accuracy: 0.8933\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4575 - accuracy: 0.8649\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6667 - accuracy: 0.8004\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4532 - accuracy: 0.8632\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3627 - accuracy: 0.8903\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4613 - accuracy: 0.8650\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6625 - accuracy: 0.8020\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4499 - accuracy: 0.8661\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3640 - accuracy: 0.8905\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.8683\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6662 - accuracy: 0.8009\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4499 - accuracy: 0.8673\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3603 - accuracy: 0.8923\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4648 - accuracy: 0.8653\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6341 - accuracy: 0.8061\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4327 - accuracy: 0.8674\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3428 - accuracy: 0.8942\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4684 - accuracy: 0.8647\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6374 - accuracy: 0.8070\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4279 - accuracy: 0.8696\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3428 - accuracy: 0.8944\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4502 - accuracy: 0.8659\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6327 - accuracy: 0.8071\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4286 - accuracy: 0.8693\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3452 - accuracy: 0.8934\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4706 - accuracy: 0.8641\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6872 - accuracy: 0.7959\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4729 - accuracy: 0.8597\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3892 - accuracy: 0.8845\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4791 - accuracy: 0.8612\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6861 - accuracy: 0.7942\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4719 - accuracy: 0.8601\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3883 - accuracy: 0.8836\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4643 - accuracy: 0.8636\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6875 - accuracy: 0.7944\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4712 - accuracy: 0.8601\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3887 - accuracy: 0.8851\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4808 - accuracy: 0.8583\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6567 - accuracy: 0.8000\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4490 - accuracy: 0.8638\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3617 - accuracy: 0.8893\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4723 - accuracy: 0.8599\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6579 - accuracy: 0.8000\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4503 - accuracy: 0.8618\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3646 - accuracy: 0.8881\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4701 - accuracy: 0.8584\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6533 - accuracy: 0.8002\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4466 - accuracy: 0.8649\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3634 - accuracy: 0.8889\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4546 - accuracy: 0.8646\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6901 - accuracy: 0.7933\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4709 - accuracy: 0.8595\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3883 - accuracy: 0.8840\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4813 - accuracy: 0.8637\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.6931 - accuracy: 0.7944\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.4744 - accuracy: 0.8590\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3915 - accuracy: 0.8819\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4787 - accuracy: 0.8587\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6863 - accuracy: 0.7950\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4699 - accuracy: 0.8615\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3870 - accuracy: 0.8852\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.4776 - accuracy: 0.8578\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6616 - accuracy: 0.7976\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4518 - accuracy: 0.8639\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3659 - accuracy: 0.8886\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4847 - accuracy: 0.8560\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6566 - accuracy: 0.8006\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4506 - accuracy: 0.8633\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3627 - accuracy: 0.8889\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 0.4543 - accuracy: 0.8667\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6596 - accuracy: 0.8001\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4510 - accuracy: 0.8627\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.3664 - accuracy: 0.8870\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.4780 - accuracy: 0.8591\n",
            "Epoch 1/3\n",
            "2344/2344 [==============================] - 7s 3ms/step - loss: 0.6140 - accuracy: 0.8162\n",
            "Epoch 2/3\n",
            "2344/2344 [==============================] - 6s 3ms/step - loss: 0.4242 - accuracy: 0.8742\n",
            "Epoch 3/3\n",
            "2344/2344 [==============================] - 7s 3ms/step - loss: 0.3487 - accuracy: 0.8963\n",
            "Best: 0.8661999901135763 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.8658799926439921, Stdev: 0.0018207686378055308 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n",
            "Means: 0.8636000156402588, Stdev: 0.001618886751630362 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8661999901135763, Stdev: 0.0015034158659117055 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.8649066686630249, Stdev: 0.0007521246640201188 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "Means: 0.8610400160153707, Stdev: 0.002176486071744249 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n",
            "Means: 0.8609866698582967, Stdev: 0.002656781343579682 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
            "Means: 0.8600533405939738, Stdev: 0.002594213791211259 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
            "Means: 0.860586682955424, Stdev: 0.004488373025866924 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n",
            "CPU times: user 6min 56s, sys: 37 s, total: 7min 33s\n",
            "Wall time: 7min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIlpwjag5yYZ"
      },
      "source": [
        "best_model = grid_result.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFvMxmr85yYZ",
        "outputId": "a1a01958-a23c-4194-e694-4ef5d5f17858"
      },
      "source": [
        "best_model.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'build_fn': <function __main__.create_model>,\n",
              " 'epochs': 3,\n",
              " 'first_layer_nodes': 500,\n",
              " 'last_layer_nodes': 50,\n",
              " 'n_layers': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X41u_hls7mNp"
      },
      "source": [
        "\n",
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ_uyKlj7mNp"
      },
      "source": [
        "def build_model(hp):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a complied keras model ready for keras-tuner gridsearch algorithms \n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=hp.get('units'),activation=hp.get(\"activation\")))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(hp.get('learning_rate')),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYE7rTku7mNp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f978a19e-3865-4722-d1a5-c9a4c88cd85e"
      },
      "source": [
        "hp = HyperParameters()\n",
        "hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n",
        "hp.Choice('activation',values=[\"relu\", \"sigmoid\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'relu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqjp2kHD7mNu"
      },
      "source": [
        "##Gridsearch Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJQFKoyL7mNu"
      },
      "source": [
        "hyper_parameters = {\n",
        "    \"units\": np.arange(32, 512, 32).tolist(), # tolist() or error\n",
        "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
        "    \"activation\":[\"relu\", \"sigmoid\"]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcxV58iC7mNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da72b020-575a-410e-d32d-cbab48083357"
      },
      "source": [
        "hyper_parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': ['relu', 'sigmoid'],\n",
              " 'learning_rate': [0.1, 0.01, 0.001],\n",
              " 'units': [32,\n",
              "  64,\n",
              "  96,\n",
              "  128,\n",
              "  160,\n",
              "  192,\n",
              "  224,\n",
              "  256,\n",
              "  288,\n",
              "  320,\n",
              "  352,\n",
              "  384,\n",
              "  416,\n",
              "  448,\n",
              "  480]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZFVl-I-7mNv"
      },
      "source": [
        "def build_model(units, learning_rate, activation):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a complie keras model ready for keras-tuner gridsearch algorithms \n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units, activation=activation))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqYmn3QFsqZ_"
      },
      "source": [
        "## Apply Keras wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABSzrTrH7mNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ded21d-e0f2-4657-c13d-31b294045f60"
      },
      "source": [
        "model = KerasClassifier(build_fn = build_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "tTawllrN7mNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc4971b-bf9a-46fe-d301-f1517205f9d3"
      },
      "source": [
        "start = time()\n",
        "\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=hyper_parameters, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "end = time()\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8609 - accuracy: 0.3186\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.8553 - accuracy: 0.3245\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9754 - accuracy: 0.2653\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.0762 - accuracy: 0.2103\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1490 - accuracy: 0.1831\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.1489 - accuracy: 0.1776\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9492 - accuracy: 0.2801\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9455 - accuracy: 0.2588\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9536 - accuracy: 0.2942\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.8512 - accuracy: 0.3336\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0618 - accuracy: 0.2297\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.0944 - accuracy: 0.1894\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9027 - accuracy: 0.3111\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.0310 - accuracy: 0.2210\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9320 - accuracy: 0.3088\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.9512 - accuracy: 0.2702\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9065 - accuracy: 0.3267\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9401 - accuracy: 0.2717\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9682 - accuracy: 0.3118\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.8545 - accuracy: 0.3297\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.1304 - accuracy: 0.2517\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 2.0973 - accuracy: 0.2331\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8879 - accuracy: 0.3306\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.7515 - accuracy: 0.3332\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8908 - accuracy: 0.3426\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.8102 - accuracy: 0.3306\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0062 - accuracy: 0.2916\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.9520 - accuracy: 0.2523\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9754 - accuracy: 0.3014\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.0715 - accuracy: 0.2524\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9467 - accuracy: 0.3428\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.0779 - accuracy: 0.2506\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1908 - accuracy: 0.2431\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.1223 - accuracy: 0.1851\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9644 - accuracy: 0.3112\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.8872 - accuracy: 0.3106\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9801 - accuracy: 0.3549\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.8228 - accuracy: 0.3161\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0851 - accuracy: 0.2920\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9722 - accuracy: 0.2367\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 2.0381 - accuracy: 0.3114\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9687 - accuracy: 0.2364\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0746 - accuracy: 0.2816\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 2.0353 - accuracy: 0.2274\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9555 - accuracy: 0.3585\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9406 - accuracy: 0.3505\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9883 - accuracy: 0.3145\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9193 - accuracy: 0.2994\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 2.0065 - accuracy: 0.3157\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.8595 - accuracy: 0.2853\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0554 - accuracy: 0.3374\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.8566 - accuracy: 0.3084\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1855 - accuracy: 0.2755\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.1078 - accuracy: 0.2480\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0594 - accuracy: 0.3300\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.8985 - accuracy: 0.3062\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.2103 - accuracy: 0.2393\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.9765 - accuracy: 0.2426\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0273 - accuracy: 0.3349\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9998 - accuracy: 0.3413\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1753 - accuracy: 0.2809\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9539 - accuracy: 0.2470\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 2.0635 - accuracy: 0.3244\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.8355 - accuracy: 0.2931\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9565 - accuracy: 0.3596\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.8329 - accuracy: 0.3425\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.1547 - accuracy: 0.3276\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.0562 - accuracy: 0.2437\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.0669 - accuracy: 0.3079\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.8592 - accuracy: 0.2896\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9867 - accuracy: 0.3947\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.9990 - accuracy: 0.3430\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0807 - accuracy: 0.3492\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9314 - accuracy: 0.3224\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1315 - accuracy: 0.3350\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9651 - accuracy: 0.2576\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.1895 - accuracy: 0.2803\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.0360 - accuracy: 0.2170\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.0077 - accuracy: 0.3673\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9116 - accuracy: 0.2898\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1203 - accuracy: 0.3103\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9993 - accuracy: 0.2302\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1553 - accuracy: 0.3425\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9132 - accuracy: 0.2790\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.1194 - accuracy: 0.3332\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 1.8362 - accuracy: 0.3036\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 2.2877 - accuracy: 0.2342\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 2.2413 - accuracy: 0.1744\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1879 - accuracy: 0.3851\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 1.9648 - accuracy: 0.2629\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8179 - accuracy: 0.7504\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7324 - accuracy: 0.7801\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8149 - accuracy: 0.7510\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.7242 - accuracy: 0.7809\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.8013 - accuracy: 0.7550\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7078 - accuracy: 0.7868\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7598 - accuracy: 0.7694\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6755 - accuracy: 0.7989\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7679 - accuracy: 0.7659\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6561 - accuracy: 0.7994\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7456 - accuracy: 0.7736\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6951 - accuracy: 0.7906\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7351 - accuracy: 0.7775\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6696 - accuracy: 0.7954\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7528 - accuracy: 0.7728\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7097 - accuracy: 0.7912\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7386 - accuracy: 0.7760\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.8004\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7398 - accuracy: 0.7749\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6759 - accuracy: 0.8006\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7474 - accuracy: 0.7720\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6784 - accuracy: 0.7982\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7391 - accuracy: 0.7742\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7138 - accuracy: 0.7890\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7409 - accuracy: 0.7762\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6310 - accuracy: 0.8147\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7436 - accuracy: 0.7739\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6549 - accuracy: 0.8072\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7405 - accuracy: 0.7793\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6828 - accuracy: 0.7974\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7368 - accuracy: 0.7777\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.8004\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7469 - accuracy: 0.7735\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.7900\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7408 - accuracy: 0.7753\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7038 - accuracy: 0.7900\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7345 - accuracy: 0.7768\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6888 - accuracy: 0.7930\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7489 - accuracy: 0.7753\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6442 - accuracy: 0.8102\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7394 - accuracy: 0.7758\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6766 - accuracy: 0.8022\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7353 - accuracy: 0.7790\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6679 - accuracy: 0.7997\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7435 - accuracy: 0.7743\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6744 - accuracy: 0.8003\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7456 - accuracy: 0.7740\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6873 - accuracy: 0.7960\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7447 - accuracy: 0.7773\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6728 - accuracy: 0.8020\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7433 - accuracy: 0.7774\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6967 - accuracy: 0.7978\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7382 - accuracy: 0.7786\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6475 - accuracy: 0.8044\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7375 - accuracy: 0.7778\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6738 - accuracy: 0.8049\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7517 - accuracy: 0.7752\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6860 - accuracy: 0.7992\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7435 - accuracy: 0.7747\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6605 - accuracy: 0.8039\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7434 - accuracy: 0.7768\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7117 - accuracy: 0.7857\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7519 - accuracy: 0.7724\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6706 - accuracy: 0.7954\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7442 - accuracy: 0.7766\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6926 - accuracy: 0.7823\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7443 - accuracy: 0.7763\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7386 - accuracy: 0.7836\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7499 - accuracy: 0.7743\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.7148 - accuracy: 0.7876\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7478 - accuracy: 0.7764\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6617 - accuracy: 0.8047\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7486 - accuracy: 0.7767\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6871 - accuracy: 0.8030\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7446 - accuracy: 0.7772\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6864 - accuracy: 0.7830\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7447 - accuracy: 0.7771\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6737 - accuracy: 0.8045\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7367 - accuracy: 0.7774\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.6618 - accuracy: 0.8050\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.7532 - accuracy: 0.7760\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6577 - accuracy: 0.8024\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7518 - accuracy: 0.7748\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6728 - accuracy: 0.7961\n",
            "1477/1563 [===========================>..] - ETA: 0s - loss: 0.7497 - accuracy: 0.7735"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THKMZLNv7mNw"
      },
      "source": [
        "total_run_time_in_miniutes = (end - start)/60\n",
        "total_run_time_in_miniutes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XgJsrZb7mNx"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYufbSI87mNx"
      },
      "source": [
        "best_model = grid_result.best_estimator_\n",
        "test_acc = best_model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlR-pVwP7mNx"
      },
      "source": [
        "test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu-lBWph7mNq"
      },
      "source": [
        "## Using Keras hyperparam tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9PCHLBWQPcb"
      },
      "source": [
        "random_tuner = RandomSearch(\n",
        "            build_model,\n",
        "            objective='val_accuracy',\n",
        "            max_trials=n_param_combos_to_sample, \n",
        "            seed=1234,\n",
        "            hyperparameters=hp, # pass in hyperparameter dictionary\n",
        "            directory='./keras-tuner-trial',\n",
        "            project_name='random_search')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGFdv1qE7mNr"
      },
      "source": [
        "random_tuner.search(X_train, y_train,\n",
        "                    epochs=3,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBUhIe97mNr"
      },
      "source": [
        "# identify the best score and hyperparamter \n",
        "random_tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NXjQBn47mNs"
      },
      "source": [
        "max_trials=24\n",
        "num_initial_points=5\n",
        "beta=5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhZNIJZ4RS5Y"
      },
      "source": [
        "#### Using BayesianOptimization class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33joO_J97mNs"
      },
      "source": [
        "bayesian_tuner = BayesianOptimization(\n",
        "                    build_model,\n",
        "                    objective='val_accuracy',\n",
        "                    max_trials=max_trials,\n",
        "                    hyperparameters=hp, # pass in our hyperparameter dictionary\n",
        "                    num_initial_points=num_initial_points, \n",
        "                    beta=beta, \n",
        "                    seed=1234,\n",
        "                    directory='./keras-tuner-trial',\n",
        "                    project_name='bayesian_optimization_4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9AM5Pdj7mNt"
      },
      "source": [
        "bayesian_tuner.search(X_train, y_train,\n",
        "               epochs=3,\n",
        "               validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "FJcHC8d87mNt"
      },
      "source": [
        "bayesian_tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}